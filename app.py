import numpy as np
import pandas as pd
import streamlit as st
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import img_to_array
from PIL import Image
import cv2

# =========================
# CONFIG
# =========================
st.set_page_config(page_title="–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤", page_icon="üå∏", layout="wide")

MODEL_PATH = "flower_best.keras"
IMG_SIZE = 224

# –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ —ç—Ç–∏—Ö –∫–ª–∞—Å—Å–∞—Ö (–∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∏–º–µ–Ω–∞ ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ)
CLASS_NAMES_EN = ["daisy", "dandelion", "rose", "sunflower", "tulip"]

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (—Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è + —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã)
CLASS_NAMES_RU = {
    "daisy": "–†–æ–º–∞—à–∫–∞",
    "dandelion": "–û–¥—É–≤–∞–Ω—á–∏–∫",
    "rose": "–†–æ–∑–∞",
    "sunflower": "–ü–æ–¥—Å–æ–ª–Ω—É—Ö",
    "tulip": "–¢—é–ª—å–ø–∞–Ω",
}


# =========================
# MODEL LOADING (robust for Grad-CAM)
# =========================
@st.cache_resource
def load_models():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π Sequential
    seq = keras.models.load_model(MODEL_PATH, compile=False)

    # "–ø—Ä–æ–≥—Ä–µ–≤" ‚Äî —á—Ç–æ–±—ã —É Sequential –ø–æ—è–≤–∏–ª—Å—è –≥—Ä–∞—Ñ/inputs/outputs
    _ = seq(tf.zeros((1, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32), training=False)

    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ Functional-–≥—Ä–∞—Ñ –Ω–∞ —Ç–µ—Ö –∂–µ —Å–ª–æ—è—Ö (–≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è)
    inp = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name="input")
    x = inp
    conv_outputs = {}  # –∏–º—è Conv2D -> —Ç–µ–Ω–∑–æ—Ä –≤—ã—Ö–æ–¥–∞

    for layer in seq.layers:
        x = layer(x)
        if isinstance(layer, tf.keras.layers.Conv2D):
            conv_outputs[layer.name] = x

    func = tf.keras.Model(inputs=inp, outputs=x, name="functional_wrapper")
    return func, conv_outputs

model, conv_outputs_map = load_models()
CONV_LAYERS = list(conv_outputs_map.keys())


# =========================
# PREPROCESS
# =========================
def preprocess_pil(pil_img: Image.Image):
    img = pil_img.convert("RGB").resize((IMG_SIZE, IMG_SIZE))
    arr = img_to_array(img).astype(np.float32) / 255.0
    arr = np.expand_dims(arr, axis=0)  # (1, 224, 224, 3)
    return arr


# =========================
# GRAD-CAM
# =========================
def make_gradcam_heatmap(x: tf.Tensor, conv_layer_name: str):
    conv_out = conv_outputs_map[conv_layer_name]  # —Ç–µ–Ω–∑–æ—Ä –∏–∑ functional-–≥—Ä–∞—Ñ–∞

    grad_model = tf.keras.Model(
        inputs=model.inputs,
        outputs=[conv_out, model.outputs[0]]
    )

    with tf.GradientTape() as tape:
        conv_outputs, preds = grad_model(x, training=False)
        tape.watch(conv_outputs)

        pred_index = tf.argmax(preds[0])
        score = preds[:, pred_index][0]

    grads = tape.gradient(score, conv_outputs)
    if grads is None:
        return None

    conv_outputs = conv_outputs[0]  # (h,w,c)
    grads = grads[0]                # (h,w,c)

    weights = tf.reduce_mean(grads, axis=(0, 1))              # (c,)
    cam = tf.reduce_sum(conv_outputs * weights, axis=-1)      # (h,w)

    cam = tf.maximum(cam, 0)
    cam = cam / (tf.reduce_max(cam) + 1e-8)
    return cam.numpy()


def overlay_heatmap_on_pil(heatmap: np.ndarray, pil_img: Image.Image, alpha=0.40):
    # resize heatmap to original image size
    w, h = pil_img.size
    heatmap_resized = cv2.resize(heatmap, (w, h))
    heatmap_uint8 = np.uint8(255 * heatmap_resized)

    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)

    img_rgb = np.array(pil_img.convert("RGB"))
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    overlay_bgr = cv2.addWeighted(heatmap_color, alpha, img_bgr, 1 - alpha, 0)
    overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)
    return overlay_rgb


def predict_with_gradcam(pil_img: Image.Image, conv_layer_preference: str | None):
    arr = preprocess_pil(pil_img)
    x = tf.convert_to_tensor(arr, dtype=tf.float32)

    probs = model(x, training=False)[0].numpy()

    class_idx = int(np.argmax(probs))
    class_name_en = CLASS_NAMES_EN[class_idx]
    class_name_ru = CLASS_NAMES_RU.get(class_name_en, class_name_en)

    if not CONV_LAYERS:
        return class_name_en, class_name_ru, probs, None, None, None

    candidates = []
    if conv_layer_preference and conv_layer_preference in CONV_LAYERS:
        candidates.append(conv_layer_preference)
    candidates += [n for n in reversed(CONV_LAYERS) if n not in candidates]

    for layer_name in candidates:
        heatmap = make_gradcam_heatmap(x, layer_name)
        if heatmap is not None:
            return class_name_en, class_name_ru, probs, heatmap, None, layer_name

    return class_name_en, class_name_ru, probs, None, None, None


# =========================
# UI
# =========================
st.title("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤ (CNN) + Grad-CAM")
st.write(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —Ü–≤–µ—Ç–∫–∞ –∏–ª–∏ —Å–¥–µ–ª–∞–π—Ç–µ —Å–Ω–∏–º–æ–∫ —Å –∫–∞–º–µ—Ä—ã."
    " –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∂–µ—Ç –∫–ª–∞—Å—Å –∏ –ø–æ–∫–∞–∂–µ—Ç –Ω–∞ –∫–∞–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–Ω–∞ –æ–ø–∏—Ä–∞–ª–∞—Å—å."
)

with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    st.markdown("**–ö–ª–∞—Å—Å—ã:**")
    for k in CLASS_NAMES_EN:
        st.write(f"- {CLASS_NAMES_RU[k]} ({k})")

    st.divider()

    if CONV_LAYERS:
        st.markdown("**–°–ª–æ–π –¥–ª—è Grad-CAM**")
        default_idx = len(CONV_LAYERS) - 1
        selected_layer = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–æ–π",
            options=CONV_LAYERS,
            index=default_idx
        )
    else:
        selected_layer = None
        st.warning("Conv2D —Å–ª–æ–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî Grad-CAM –æ—Ç–∫–ª—é—á—ë–Ω.")

    alpha = st.slider("–ù–∞–ª–æ–∂–µ–Ω–∏–µ heatmap (alpha)", 0.0, 0.9, 0.40, 0.05)
    img_width = st.slider("–®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", 250, 900, 520, 10)

st.markdown("### –í–≤–æ–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
col_upload, col_cam = st.columns(2)

with col_upload:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (JPG/PNG)", type=["jpg", "jpeg", "png"])

with col_cam:
    camera_image = st.camera_input("–ò–ª–∏ —Å–¥–µ–ª–∞—Ç—å —Å–Ω–∏–º–æ–∫ —Å –∫–∞–º–µ—Ä—ã")

pil_image = None
if camera_image is not None:
    pil_image = Image.open(camera_image).convert("RGB")
elif uploaded_file is not None:
    pil_image = Image.open(uploaded_file).convert("RGB")

if pil_image is None:
    st.info("–ü–æ–∫–∞ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª –∏–ª–∏ —Å–¥–µ–ª–∞–π —Ñ–æ—Ç–æ.")
    st.stop()

# Predict + Grad-CAM
pred_en, pred_ru, probs, heatmap, overlay, used_layer = predict_with_gradcam(pil_image, selected_layer)

# –ï—Å–ª–∏ –ø–æ—Å—Ç—Ä–æ–∏–ª–∏ heatmap ‚Äî –Ω–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º alpha
if heatmap is not None:
    overlay = overlay_heatmap_on_pil(heatmap, pil_image, alpha=alpha)

# Layout
c1, c2, c3 = st.columns([1.2, 1.2, 1])

with c1:
    st.markdown("### –û—Ä–∏–≥–∏–Ω–∞–ª")
    st.image(pil_image, width=img_width)

with c2:
    st.markdown("### Grad-CAM")
    if overlay is None:
        st.warning("Grad-CAM –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π conv-—Å–ª–æ–π –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    else:
        st.image(overlay, width=img_width)
        st.caption(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–π: `{used_layer}`")

with c3:
    st.markdown("### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
    st.markdown(f"**–ö–ª–∞—Å—Å:** {pred_ru}")
    st.caption(f"–ê–Ω–≥–ª.: {pred_en}")

    df = pd.DataFrame({
        "–ö–ª–∞—Å—Å": [CLASS_NAMES_RU[c] for c in CLASS_NAMES_EN],
        "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å": probs
    }).set_index("–ö–ª–∞—Å—Å")

    st.bar_chart(df)

    st.caption(
        "–¢—ë–ø–ª—ã–µ –∑–æ–Ω—ã –Ω–∞ Grad-CAM –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ–±–ª–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –ø–æ–≤–ª–∏—è–ª–∏ –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏."
    )
